{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This notebook gives you a basic overview of data wrangling which involves data cleaning and investigating its properties. Followed by model building and validating it.\n",
    "\n",
    "We will use a movie data which can be downloaded at [http://bit.ly/cs109_imdb](http://bit.ly/cs109_imdb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Build a DataFrame\n",
    "\n",
    "The textfile is tab-separated, and doesn't have any column headers. We\n",
    "set the appropriate keywords in `pd.read_csv` to handle this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['imdbID', 'title', 'year', 'score', 'votes', 'runtime', 'genres']\n",
    "data = pd.read_csv('imdb_top_10000.txt', delimiter='\\t', names=names).dropna()\n",
    "print(\"Number of rows: %i\" % data.shape[0])\n",
    "data.head()  # print the first 5 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Clean the DataFrame\n",
    "\n",
    "There are several problems with the DataFrame at this point:\n",
    "\n",
    "1. The runtime column describes a number, but is stored as a string\n",
    "2. The genres column is not atomic -- it aggregates several genres together. This makes it hard, for example, to extract which movies are Comedies.\n",
    "3. The movie year is repeated in the title and year column\n",
    "\n",
    "### Fixing the runtime column\n",
    "\n",
    "The following snipptet converts a string like '142 mins.' to the number 142:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty = '142 mins.'\n",
    "number, text = dirty.split(' ')\n",
    "clean = int(number)\n",
    "print (number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can package this up into a list comprehension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_runtime = [float(r.split(' ')[0]) for r in data.runtime]\n",
    "data['runtime'] = clean_runtime\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting up the genres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the concept of *indicator variables* to split the genres column into many columns. Each new column will correspond to a single genre, and each cell will be True or False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#determine the unique genres\n",
    "genres = set()\n",
    "for m in data.genres:\n",
    "    genres.update(g for g in m.split('|'))\n",
    "genres = sorted(genres)\n",
    "\n",
    "#make a column for each genre\n",
    "for genre in genres:\n",
    "    data[genre] = [genre in movie.split('|') for movie in data.genres]\n",
    "         \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing year from the title\n",
    "We can fix each element by stripping off the last 7 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['title'] = [t[0:-7] for t in data.title]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Explore global properties\n",
    "\n",
    "Next, we get a handle on some basic, global summaries of the DataFrame.\n",
    "\n",
    "### Call `describe` on relevant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['score', 'runtime', 'year', 'votes']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hmmm, a runtime of 0 looks suspicious. How many movies have that?\n",
    "print (len(data[data.runtime == 0]))\n",
    "\n",
    "#probably best to flag those bad data as NAN\n",
    "data.runtime[data.runtime==0] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After flagging bad runtimes, we repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.runtime.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make some basic plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# more movies in recent years, but not *very* recent movies (they haven't had time to receive lots of votes yet?)\n",
    "plt.hist(data.year, bins=np.arange(1950, 2013), color='#cccccc')\n",
    "plt.xlabel(\"Release Year\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(data.score, bins=20, color='#cccccc')\n",
    "plt.xlabel(\"IMDB rating\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(data.runtime.dropna(), bins=50, color='#cccccc')\n",
    "plt.xlabel(\"Runtime distribution\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hmm, more bad, recent movies. Real, or a selection bias?\n",
    "\n",
    "plt.scatter(data.year, data.score, lw=0, alpha=.08, color='k')\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"IMDB Rating\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(data.votes, data.score, lw=0, alpha=.2, color='k')\n",
    "plt.xlabel(\"Number of Votes\")\n",
    "plt.ylabel(\"IMDB Rating\")\n",
    "plt.xscale('log')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify some outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# low-score movies with lots of votes\n",
    "data[(data.votes > 9e4) & (data.score < 5)][['title', 'year', 'score', 'votes', 'genres']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The lowest rated movies\n",
    "data[data.score == data.score.min()][['title', 'year', 'score', 'votes', 'genres']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The highest rated movies\n",
    "data[data.score == data.score.max()][['title', 'year', 'score', 'votes', 'genres']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run aggregation functions like `sum` over several rows or columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*What genres are the most frequent?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sum sums over rows by default\n",
    "genre_count = np.sort(data[genres].sum())[::-1]\n",
    "pd.DataFrame({'Genre Count': genre_count})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*How many genres does a movie have, on average?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#axis=1 sums over columns instead\n",
    "genre_count = data[genres].sum(axis=1) \n",
    "print (\"Average movie has %0.2f genres\" % genre_count.mean())\n",
    "genre_count.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Group Properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's split up movies by decade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decade =  (data.year // 10) * 10\n",
    "\n",
    "tyd = data[['title', 'year']]\n",
    "tyd['decade'] = decade\n",
    "\n",
    "tyd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[GroupBy](http://pandas.pydata.org/pandas-docs/dev/groupby.html) will gather movies into groups with equal decade values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean score for all movies in each decade\n",
    "decade_mean = data.groupby(decade).score.mean()\n",
    "decade_mean.name = 'Decade Mean'\n",
    "print (decade_mean)\n",
    "\n",
    "plt.plot(decade_mean.index, decade_mean.values, 'o-',\n",
    "        color='r', lw=3, label='Decade Average')\n",
    "plt.scatter(data.year, data.score, alpha=.04, lw=0, color='k')\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.legend(frameon=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can go one further, and compute the scatter in each year as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_scores = data.groupby(decade).score\n",
    "\n",
    "mean = grouped_scores.mean()\n",
    "std = grouped_scores.std()\n",
    "\n",
    "plt.plot(decade_mean.index, decade_mean.values, 'o-',\n",
    "        color='r', lw=3, label='Decade Average')\n",
    "plt.fill_between(decade_mean.index, (decade_mean + std).values,\n",
    "                 (decade_mean - std).values, color='r', alpha=.2)\n",
    "plt.scatter(data.year, data.score, alpha=.04, lw=0, color='k')\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.legend(frameon=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also iterate over a GroupBy object. Each iteration yields two variables: one of the distinct values of the group key, and the subset of the dataframe where the key equals that value. To find the most popular movie each year:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year, subset in data.groupby('year'):\n",
    "    print (year, subset[subset.score == subset.score.max()].title.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Small multiples\n",
    "\n",
    "Let's split up the movies by genre, and look at how their release year/runtime/IMDB score vary.\n",
    "The distribution for all movies is shown as a grey background.\n",
    "\n",
    "This isn't a standard groupby, so we can't use the `groupby` method here. A manual loop is needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a 4x6 grid of plots.\n",
    "fig, axes = plt.subplots(nrows=4, ncols=6, figsize=(12, 8), \n",
    "                         tight_layout=True)\n",
    "\n",
    "bins = np.arange(1950, 2013, 3)\n",
    "for ax, genre in zip(axes.ravel(), genres):\n",
    "    ax.hist(data[data[genre] == 1].year, \n",
    "            bins=bins, histtype='stepfilled', normed=True, color='r', alpha=.3, ec='none')\n",
    "    ax.hist(data.year, bins=bins, histtype='stepfilled', ec='None', normed=True, zorder=0, color='#cccccc')\n",
    "    \n",
    "    ax.annotate(genre, xy=(1955, 3e-2), fontsize=14)\n",
    "    ax.xaxis.set_ticks(np.arange(1950, 2013, 30))\n",
    "    ax.set_yticks([])\n",
    " \n",
    "    ax.set_xlabel('Year')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some subtler patterns here:\n",
    "\n",
    "1. Westerns and Musicals have a more level distribution\n",
    "2. Film Noir movies were much more popular in the 50s and 60s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=4, ncols=6, figsize=(12, 8), tight_layout=True)\n",
    "\n",
    "bins = np.arange(30, 240, 10)\n",
    "\n",
    "for ax, genre in zip(axes.ravel(), genres):\n",
    "    ax.hist(data[data[genre] == 1].runtime, \n",
    "            bins=bins, histtype='stepfilled', color='r', ec='none', alpha=.3, normed=True)\n",
    "               \n",
    "    ax.hist(data.runtime, bins=bins, normed=True,\n",
    "            histtype='stepfilled', ec='none', color='#cccccc',\n",
    "            zorder=0)\n",
    "    \n",
    "    ax.set_xticks(np.arange(30, 240, 60))\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xlabel(\"Runtime [min]\")\n",
    "\n",
    "    ax.annotate(genre, xy=(230, .02), ha='right', fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Biographies and history movies are longer\n",
    "1. Animated movies are shorter\n",
    "1. Film-Noir movies have the same mean, but are more conentrated around a 100 minute runtime\n",
    "1. Musicals have the same mean, but greater dispersion in runtimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=4, ncols=6, figsize=(12, 8), tight_layout=True)\n",
    "\n",
    "bins = np.arange(0, 10, .5)\n",
    "\n",
    "for ax, genre in zip(axes.ravel(), genres):\n",
    "    ax.hist(data[data[genre] == 1].score, \n",
    "            bins=bins, histtype='stepfilled', color='r', ec='none', alpha=.3, normed=True)\n",
    "               \n",
    "    ax.hist(data.score, bins=bins, normed=True,\n",
    "            histtype='stepfilled', ec='none', color='#cccccc',\n",
    "            zorder=0)\n",
    "    \n",
    "    ax.set_yticks([])\n",
    "    ax.set_xlabel(\"Score\")\n",
    "  \n",
    "    ax.set_ylim(0, .4)\n",
    "    ax.annotate(genre, xy=(0, .2), ha='left', fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Film-noirs, histories, and biographies have higher ratings\n",
    "Horror movies and adult films have lower ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "movie_df=data\n",
    "print(movie_df.head(3))\n",
    "\n",
    "movie_df=movie_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to categorize the imdb values in the range of 0-4,4-6,6-8 and 8-10 to mark them as the bad,average,good and excellent movies respectively\n",
    "\n",
    "movie_df[\"imdb_binned_score\"]=pd.cut(movie_df['score'], bins=[0,4,6,8,10], right=True, labels=False)+1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model building and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test sets to build the model. The model is trained on train set and validated on test set\n",
    "X=pd.DataFrame(columns=[ 'year', 'score', 'votes', 'runtime', \n",
    "        'Action', 'Adult', 'Adventure', 'Animation', 'Biography', 'Comedy',\n",
    "        'Crime', 'Drama', 'Family', 'Fantasy', 'Film-Noir', 'History', 'Horror',\n",
    "        'Music', 'Musical', 'Mystery', 'News', 'Reality-TV', 'Romance',\n",
    "        'Sci-Fi', 'Sport', 'Thriller', 'War', 'Western'],data=movie_df)\n",
    "y=pd.DataFrame(columns=['imdb_binned_score'],data=movie_df)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.3,random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try out Logistic Regression and check its performance by plotting confusion matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logit =LogisticRegression()\n",
    "logit.fit(X_train,np.ravel(y_train,order='C'))\n",
    "y_pred=logit.predict(X_test)\n",
    "\n",
    "\n",
    "from sklearn import metrics\n",
    "cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(cnf_matrix)\n",
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try out KNN and check its performance by plotting confusion matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=22)\n",
    "knn.fit(X_train, np.ravel(y_train,order='C'))\n",
    "knnpred = knn.predict(X_test)\n",
    "cnf_matrix = metrics.confusion_matrix(y_test, knnpred)\n",
    "print(cnf_matrix)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, knnpred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try out NAive Bayes and check its performance by plotting confusion matrix\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gaussiannb= GaussianNB()\n",
    "gaussiannb.fit(X_train, np.ravel(y_train,order='C'))\n",
    "gaussiannbpred = gaussiannb.predict(X_test)\n",
    "cnf_matrix = metrics.confusion_matrix(y_test, gaussiannbpred)\n",
    "print(cnf_matrix)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, gaussiannbpred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's try out Decision Tree and check its performance by plotting confusion matrix\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtree = DecisionTreeClassifier(criterion='gini') #criterion = entopy, gini\n",
    "dtree.fit(X_train, np.ravel(y_train,order='C'))\n",
    "dtreepred = dtree.predict(X_test)\n",
    "cnf_matrix = metrics.confusion_matrix(y_test, dtreepred)\n",
    "print(cnf_matrix)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, dtreepred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
